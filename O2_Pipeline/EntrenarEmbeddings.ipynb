{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import sentencepiece as spm\n",
    "\n",
    "df_corpus = pd.read_json('https://raw.githubusercontent.com/Xnehil/Tesis/main/O1_Corpus/corpus.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'FuncionesPipeline' from 'd:\\\\Repositorios\\\\Tesis\\\\O2_Pipeline\\\\FuncionesPipeline.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import FuncionesPipeline as fp\n",
    "#Para recargar el mÃ³dulo durante el desarrollo\n",
    "importlib.reload(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Internal: could not parse ModelProto from tokenizadorEspaniol.model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m oracionesIskonawa\u001b[38;5;241m=\u001b[39mfp\u001b[38;5;241m.\u001b[39metapa_preprocesamiento(oracionesIskonawa, tokenizadorIskonawa)\n\u001b[0;32m      5\u001b[0m oracionesEspaniol\u001b[38;5;241m=\u001b[39mdf_corpus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfree_translation\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m tokenizadorEspaniol\u001b[38;5;241m=\u001b[39m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescargarTokenizador\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEspaniol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m oracionesEspaniol\u001b[38;5;241m=\u001b[39mfp\u001b[38;5;241m.\u001b[39metapa_preprocesamiento(oracionesEspaniol, tokenizadorEspaniol)\n",
      "File \u001b[1;32md:\\Repositorios\\Tesis\\O2_Pipeline\\FuncionesPipeline.py:79\u001b[0m, in \u001b[0;36mdescargarTokenizador\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     76\u001b[0m     vocab_file\u001b[38;5;241m.\u001b[39mwrite(vocab_response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m     78\u001b[0m sp \u001b[38;5;241m=\u001b[39m spm\u001b[38;5;241m.\u001b[39mSentencePieceProcessor()\n\u001b[1;32m---> 79\u001b[0m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokenizador\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sp\n",
      "File \u001b[1;32mc:\\Users\\Maracuya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentencepiece\\__init__.py:961\u001b[0m, in \u001b[0;36mSentencePieceProcessor.Load\u001b[1;34m(self, model_file, model_proto)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_proto:\n\u001b[0;32m    960\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLoadFromSerializedProto(model_proto)\n\u001b[1;32m--> 961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maracuya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentencepiece\\__init__.py:316\u001b[0m, in \u001b[0;36mSentencePieceProcessor.LoadFromFile\u001b[1;34m(self, arg)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadFromFile\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sentencepiece\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentencePieceProcessor_LoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Internal: could not parse ModelProto from tokenizadorEspaniol.model"
     ]
    }
   ],
   "source": [
    "tokenizadorIskonawa=fp.descargarTokenizador('Iskonawa')\n",
    "oracionesIskonawa=df_corpus['transcription']\n",
    "oracionesIskonawa=fp.etapa_preprocesamiento(oracionesIskonawa, tokenizadorIskonawa)\n",
    "\n",
    "oracionesEspaniol=df_corpus['free_translation']\n",
    "tokenizadorEspaniol=fp.descargarTokenizador('Espaniol')\n",
    "oracionesEspaniol=fp.etapa_preprocesamiento(oracionesEspaniol, tokenizadorEspaniol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
