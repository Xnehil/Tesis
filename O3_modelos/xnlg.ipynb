{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Path to the text file\n",
    "txt_path = '../O2_Pipeline/oracionesIskonawa.txt'\n",
    "\n",
    "# Read the text file\n",
    "with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Tokenize the text (this example uses a simple whitespace tokenizer)\n",
    "tokens = re.findall(r'\\S+', text)\n",
    "\n",
    "# Count the frequency of each token\n",
    "token_counts = Counter(tokens)\n",
    "\n",
    "# Write the tokens and their counts to vocab.txt\n",
    "with open('vocab.txt', 'w', encoding='utf-8') as f:\n",
    "    for token, count in token_counts.items():\n",
    "        f.write(f\"{token}\\n{count}\\n\")\n",
    "\n",
    "print(\"vocab.txt has been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepara data \n",
    "import subprocess\n",
    "\n",
    "# Define the paths to the vocabulary and text files\n",
    "voc_path = 'vocab.txt'\n",
    "txt_path = 'train.txt'\n",
    "\n",
    "# Construct the command\n",
    "command = ['python', 'preprocess/preprocess.py', voc_path, txt_path]\n",
    "\n",
    "# Run the command in a try-except block\n",
    "try:\n",
    "    result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "    print(\"Command executed successfully\")\n",
    "    print(\"Output:\\n\", result.stdout)\n",
    "    print(\"Error (if any):\\n\", result.stderr)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"An error occurred while executing the command\")\n",
    "    print(\"Return code:\", e.returncode)\n",
    "    print(\"Output:\\n\", e.stdout)\n",
    "    print(\"Error:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo https://dl.fbaipublicfiles.com/XLM/mlm_tlm_xnli15_1024.pth\n",
    "#BPE https://dl.fbaipublicfiles.com/XLM/codes_xnli_15\n",
    "#Vocab https://dl.fbaipublicfiles.com/XLM/vocab_xnli_15\n",
    "\n",
    "#Descargar en XNLG/base \n",
    "!wget https://dl.fbaipublicfiles.com/XLM/mlm_tlm_xnli15_1024.pth\n",
    "!wget https://dl.fbaipublicfiles.com/XLM/codes_xnli_15\n",
    "!wget https://dl.fbaipublicfiles.com/XLM/vocab_xnli_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the command as a list of arguments\n",
    "command = [\n",
    "    \"python\", \"-m\", \"torch.distributed.launch\", \"--nproc_per_node=4\", \"xnlg-train.py\",\n",
    "    \"--exp_name\", \"stage1_en-zh-fr\",\n",
    "    \"--dump_path\", \"./dump\",\n",
    "    \"--data_path\", \"./data/processed/XNLG\",\n",
    "    \"--lgs\", \"en-fr-zh\",\n",
    "    \"--mlm_steps\", \"en,zh,fr,en-fr,en-zh\",\n",
    "    \"--emb_dim\", \"1024\",\n",
    "    \"--n_layers\", \"12\",\n",
    "    \"--n_heads\", \"16\",\n",
    "    \"--dropout\", \"0.1\",\n",
    "    \"--attention_dropout\", \"0.1\",\n",
    "    \"--gelu_activation\", \"true\",\n",
    "    \"--batch_size\", \"32\",\n",
    "    \"--bptt\", \"256\",\n",
    "    \"--optimizer\", \"adam,lr=0.0001\",\n",
    "    \"--epoch_size\", \"300000\",\n",
    "    \"--max_epoch\", \"100000\",\n",
    "    \"--validation_metrics\", \"_valid_mlm_ppl\",\n",
    "    \"--stopping_criterion\", \"_valid_mlm_ppl,25\",\n",
    "    \"--fp16\", \"true\"\n",
    "]\n",
    "\n",
    "# Run the command in a try-except block\n",
    "try:\n",
    "    result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "    print(\"Command executed successfully\")\n",
    "    print(\"Output:\\n\", result.stdout)\n",
    "    print(\"Error (if any):\\n\", result.stderr)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"An error occurred while executing the command\")\n",
    "    print(\"Return code:\", e.returncode)\n",
    "    print(\"Output:\\n\", e.stdout)\n",
    "    print(\"Error:\\n\", e.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descargas etapa 2\n",
    "#Modelo https://drive.google.com/uc?export=download&confirm=1bsX&id=1LKXlEHsCOpt1NOEpjXy1XbXqVk3gZGZQ\n",
    "#BPE https://drive.google.com/uc?authuser=0&id=1nEIWJQlLD26vPt_22pDnEZSJ4mIjssps&export=download\n",
    "#Vocab https://drive.google.com/uc?id=1lIERR1ejW7_LV2rL9fFNkEhzmr7jooRx&export=download\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the command as a list of arguments\n",
    "command = [\n",
    "    \"python\", \"-m\", \"torch.distributed.launch\", \"--nproc_per_node=4\", \"xnlg-train.py\",\n",
    "    \"--exp_name\", \"stage2_en-zh-fr\",\n",
    "    \"--dump_path\", \"./dump\",\n",
    "    \"--data_path\", \"./data/processed/XNLG\",\n",
    "    \"--lgs\", \"ar-bg-de-el-en-es-fr-hi-ru-sw-th-tr-ur-vi-zh\",\n",
    "    \"--mt_steps\", \"en-zh,zh-en,en-fr,fr-en\",\n",
    "    \"--ae_steps\", \"en,zh,fr\",\n",
    "    \"--reload_model\", \"/path/to/mlm_tlm_xnli15_1024.pth,/path/to/mlm_tlm_xnli15_1024.pth\",\n",
    "    \"--emb_dim\", \"1024\",\n",
    "    \"--n_layers\", \"6\",\n",
    "    \"--n_heads\", \"8\",\n",
    "    \"--dropout\", \"0.1\",\n",
    "    \"--attention_dropout\", \"0.1\",\n",
    "    \"--gelu_activation\", \"True\",\n",
    "    \"--batch_size\", \"16\",\n",
    "    \"--bptt\", \"256\",\n",
    "    \"--optimizer\", \"adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001\",\n",
    "    \"--epoch_size\", \"10000\",\n",
    "    \"--max_vocab\", \"95000\",\n",
    "    \"--encoder_only\", \"False\",\n",
    "    \"--train_model_names\", \"decoder\",\n",
    "    \"--stopping_criterion\", \"valid_en-zh_mt_bleu,25\",\n",
    "    \"--validation_metrics\", \"valid_en-zh_mt_bleu,valid_en-fr_mt_bleu\",\n",
    "    \"--eval_bleu\", \"True\",\n",
    "    \"--word_shuffle\", \"3\",\n",
    "    \"--word_dropout\", \"0.1\",\n",
    "    \"--word_blank\", \"0.1\",\n",
    "    \"--lambda_ae\", \"0.5\",\n",
    "    \"--n_enc_layers\", \"10\"\n",
    "]\n",
    "\n",
    "# Run the command in a try-except block\n",
    "try:\n",
    "    result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "    print(\"Command executed successfully\")\n",
    "    print(\"Output:\\n\", result.stdout)\n",
    "    print(\"Error (if any):\\n\", result.stderr)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"An error occurred while executing the command\")\n",
    "    print(\"Return code:\", e.returncode)\n",
    "    print(\"Output:\\n\", e.stdout)\n",
    "    print(\"Error:\\n\", e.stderr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
