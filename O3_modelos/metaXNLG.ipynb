{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p /workspace/miniconda3\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /workspace/miniconda3/miniconda.sh\n",
    "bash /workspace/miniconda3/miniconda.sh -b -u -p /workspace/miniconda3\n",
    "rm /workspace/miniconda3/miniconda.sh\n",
    "\n",
    "/workspace/miniconda3/bin/conda init bash\n",
    "/workspace/miniconda3/bin/conda init zsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda env create --file environment.yml\n",
    "conda activate py37_ZmBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar -xf xlsum.zip -C checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretrain\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "# # Define the variables\n",
    "# PRETRAIN = \"checkpoints/xlsum/pytorch_model\"\n",
    "# langs = \"ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN\"\n",
    "# SRC = \"isk\"\n",
    "# TGT = \"isk\"\n",
    "# NAME = \"isk-isk\"\n",
    "# DATADIR = \"../dataset/postprocess/aux/isk-isk\"\n",
    "# SAVEDIR = \"checkpoints/checkpoint_ZmT5\"\n",
    "\n",
    "# # Construct the command\n",
    "# command = [\n",
    "#     \"python\", \"-u\", \"../ZmBART/train.py\", DATADIR,\n",
    "#     \"--arch\", \"t5\",\n",
    "#     \"--task\", \"translation_from_pretrained_bart\",\n",
    "#     \"--source-lang\", SRC,\n",
    "#     \"--target-lang\", TGT,\n",
    "#     \"--criterion\", \"label_smoothed_cross_entropy\",\n",
    "#     \"--label-smoothing\", \"0.2\",\n",
    "#     \"--optimizer\", \"adam\",\n",
    "#     \"--adam-eps\", \"1e-06\",\n",
    "#     \"--lr-scheduler\", \"polynomial_decay\",\n",
    "#     \"--lr\", \"3e-05\",\n",
    "#     \"--warmup-updates\", \"2500\",\n",
    "#     \"--max-update\", \"100000\",\n",
    "#     \"--dropout\", \"0.3\",\n",
    "#     \"--max-tokens\", \"2048\",\n",
    "#     \"--update-freq\", \"2\",\n",
    "#     \"--save-interval\", \"6\",\n",
    "#     \"--save-interval-updates\", \"50000\",\n",
    "#     \"--keep-interval-updates\", \"4\",\n",
    "#     \"--seed\", \"222\",\n",
    "#     \"--log-interval\", \"100\",\n",
    "#     \"--restore-file\", SAVEDIR,\n",
    "#     \"--langs\", langs,\n",
    "#     \"--save-dir\", SAVEDIR,\n",
    "#     \"--skip-invalid-size-inputs-valid-test\"\n",
    "# ]\n",
    "\n",
    "# # Monkey patch np.float to np.float64\n",
    "# # np.float = np.float64\n",
    "# print(\"Running command:\", \" \".join(command))\n",
    "\n",
    "# # Monkey patch np.float to np.float64\n",
    "# np.float = np.float64\n",
    "\n",
    "# # Run the command with error handling\n",
    "# try:\n",
    "#     result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "#     print(\"Command output:\", result.stdout)\n",
    "#     print(\"Command error (if any):\", result.stderr)\n",
    "# except subprocess.CalledProcessError as e:\n",
    "#     print(\"An error occurred while running the command.\")\n",
    "#     print(\"Return code:\", e.returncode)\n",
    "#     print(\"Output:\", e.output)\n",
    "#     print(\"Error:\", e.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# Define variables\n",
    "PRETRAIN = \"puntoChecks/xlsum\"\n",
    "langs = \"ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN\"\n",
    "SRC = \"isk\"\n",
    "TGT = \"isk\"\n",
    "NAME = \"isk-isk\"\n",
    "DATADIR = \"../data\"\n",
    "SAVEDIR = \"puntoChecks/checkpoint_ZmT5\"\n",
    "\n",
    "tokenizer = MT5Tokenizer.from_pretrained(\"puntoChecks\")\n",
    "\n",
    "def load_pre_tokenized_data(source_file, target_file, max_length=10):\n",
    "    with open(source_file, 'r', encoding=\"utf-8\") as src_f, open(target_file, 'r', encoding=\"utf-8\") as tgt_f:\n",
    "        source_lines = src_f.readlines()\n",
    "        target_lines = tgt_f.readlines()\n",
    "        \n",
    "    # Convert data into a format compatible with Hugging Face's Dataset\n",
    "    data = {\n",
    "        \"input_ids\": [\n",
    "            tokenizer.encode(src.strip(), max_length=max_length, padding='max_length', truncation=True) for src in source_lines\n",
    "        ],\n",
    "        \"labels\": [\n",
    "            tokenizer.encode(tgt.strip(), max_length=max_length, padding='max_length', truncation=True) for tgt in target_lines\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "# Load pre-tokenized train and test data\n",
    "train_dataset = load_pre_tokenized_data(f\"{DATADIR}/train.spm.isk\", f\"{DATADIR}/train.isk.target\")\n",
    "test_dataset = load_pre_tokenized_data(f\"{DATADIR}/test.spm.isk\", f\"{DATADIR}/test.isk.target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# Load pretrained tokenizer and model\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(PRETRAIN)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=SAVEDIR,                # Directory for checkpoints\n",
    "    evaluation_strategy=\"steps\",       # Evaluate every few steps\n",
    "    learning_rate=3e-05,               # As per your command\n",
    "    per_device_train_batch_size=64,    # Adjust based on memory\n",
    "    per_device_eval_batch_size=64,     # Adjust based on memory\n",
    "    weight_decay=0.01,                 # Helps in regularization\n",
    "    save_steps=5000,                   # Save checkpoint every 5000 steps\n",
    "    save_total_limit=2,                # Keep only last 4 checkpoints\n",
    "    num_train_epochs=150,                # Number of epochs                 # Based on your max update\n",
    "    warmup_steps=2500,                 # For warmup updates\n",
    "    logging_dir=\"./logs\",              # Directory for logging\n",
    "    logging_steps=100,                 # Log every 100 steps\n",
    "    label_smoothing_factor=0.2,        # For label smoothing\n",
    "    gradient_accumulation_steps=2,     # To simulate a larger batch size\n",
    "    adam_epsilon=1e-06,                # Epsilon for Adam optimizer\n",
    "    lr_scheduler_type=\"polynomial\",    # Learning rate scheduler\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model and tokenizer\n",
    "model.save_pretrained(SAVEDIR)\n",
    "tokenizer.save_pretrained(SAVEDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the environment variables\n",
    "env_vars = {\n",
    "    \"task_name\": \"sum\",\n",
    "    \"input_data_dir_name\": \"xlsum\",\n",
    "    \"BASE_DIR\": \".\",\n",
    "    \"input_dir\": \"XLSum_input/\",\n",
    "    \"output_dir\": \"outputs/xlsum_out\",\n",
    "    \"model_type\": \"t5\",\n",
    "    \"model_chkpt\": \"ZmT5_checkpoint\",\n",
    "    \"cache_dir\": \"../cache_dir\",\n",
    "    \"config_file_name\": \"auxi_tgt_lang_config\",\n",
    "}\n",
    "\n",
    "# Create the command to run\n",
    "command = [\n",
    "    \"python\", \"train.py\",\n",
    "    \"--input_dir\", f\"{env_vars['input_dir']}{env_vars['input_data_dir_name']}\",\n",
    "    \"--output_dir\", env_vars['output_dir'],\n",
    "    \"--model_type\", env_vars['model_type'],\n",
    "    \"--model_chkpt\", env_vars['model_chkpt'],\n",
    "    \"--max_source_length\", \"512\",\n",
    "    \"--max_target_length\", \"84\",\n",
    "    \"--train_batch_size\", \"4\",\n",
    "    \"--learning_rate\", \"1e-4\",\n",
    "    \"--meta_lr\", \"1e-5\",\n",
    "    \"--weight_decay\", \"0.01\",\n",
    "    \"--adam_epsilon\", \"1e-08\",\n",
    "    \"--num_train_epochs\", \"10\",\n",
    "    \"--logging_steps\", \"10\",\n",
    "    \"--save_steps\", \"1\",\n",
    "    \"--cache_dir\", env_vars['cache_dir'],\n",
    "    \"--read_n_data_obj\", \"1000\",\n",
    "    \"--task_name\", env_vars['task_name'],\n",
    "    \"--freeze_embeds_and_decoder\",\n",
    "    \"--task_data_name\", env_vars['input_data_dir_name'],\n",
    "    \"--config_file_name\", env_vars['config_file_name'],\n",
    "    \"--n_inner_iter\", \"2\",\n",
    "]\n",
    "\n",
    "# Run the command in a subprocess with error handling\n",
    "try:\n",
    "    result = subprocess.run(command, env={**env_vars, **os.environ}, capture_output=True, text=True, check=True)\n",
    "    \n",
    "    # Print the output if the command is successful\n",
    "    print(\"Output:\", result.stdout)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    # Handle the case where the subprocess returns a non-zero exit status\n",
    "    print(\"Error: The command failed with the following message:\")\n",
    "    print(\"Output:\", e.stdout)\n",
    "    print(\"Error:\", e.stderr)\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any other exceptions\n",
    "    print(\"An unexpected error occurred:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The command failed with the following message:\n",
      "Output: \n",
      "Error: Traceback (most recent call last):\n",
      "  File \"train.py\", line 40, in <module>\n",
      "    from utils_trans import (\n",
      "  File \"/workspace/Tesis/O3_modelos/Meta_XNLG/utils_trans.py\", line 18, in <module>\n",
      "    from sacrebleu import corpus_bleu\n",
      "  File \"/workspace/Tesis/O3_modelos/Meta_XNLG/sacrebleu/__init__.py\", line 25, in <module>\n",
      "    from .tokenizers import TOKENIZERS, DEFAULT_TOKENIZER\n",
      "  File \"/workspace/Tesis/O3_modelos/Meta_XNLG/sacrebleu/tokenizers/__init__.py\", line 10, in <module>\n",
      "    from .tokenizer_indic import TokenizerIndic\n",
      "  File \"/workspace/Tesis/O3_modelos/Meta_XNLG/sacrebleu/tokenizers/tokenizer_indic.py\", line 3, in <module>\n",
      "    from indicnlp.tokenize import indic_tokenize \n",
      "ModuleNotFoundError: No module named 'indicnlp'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "# Define the environment variables\n",
    "env_vars = {\n",
    "    \"seed\": \"1234\",\n",
    "    \"task_name\": \"sum\",\n",
    "    \"input_data_dir_name\": \"xlsum\",\n",
    "    \"BASE_DIR\": \".\",\n",
    "    \"input_dir\": \"../XLSum_input/\",\n",
    "    \"output_dir\": \"outputs/xlsum_14\",\n",
    "    \"gen_file_name\": \"pred.tsv\",\n",
    "    \"cache_dir\": \"../cache_dir\",\n",
    "    \"model_type\": \"t5\",\n",
    "    \"model_chkpt\": \"outputs/xlsum\",\n",
    "}\n",
    "\n",
    "# Create the command to run\n",
    "command = [\n",
    "    \"python\", \"train.py\",\n",
    "    \"--input_dir\", f\"{env_vars['input_dir']}{env_vars['input_data_dir_name']}\",\n",
    "    \"--output_dir\", env_vars['output_dir'],\n",
    "    \"--model_type\", env_vars['model_type'],\n",
    "    \"--model_chkpt\", env_vars['model_chkpt'],\n",
    "    \"--test_batch_size\", \"32\",\n",
    "    \"--max_source_length\", \"512\",\n",
    "    \"--max_target_length\", \"84\",\n",
    "    \"--length_penalty\", \"0.6\",\n",
    "    \"--beam_size\", \"4\",\n",
    "    \"--early_stopping\",\n",
    "    \"--num_of_return_seq\", \"1\",\n",
    "    \"--min_generated_seq_len\", \"0\",\n",
    "    \"--max_generated_seq_len\", \"200\",\n",
    "    \"--cache_dir\", env_vars['cache_dir'],\n",
    "    \"--read_n_data_obj\", \"-1\",\n",
    "    \"--gen_file_name\", env_vars['gen_file_name'],\n",
    "    \"--task_name\", env_vars['task_name'],\n",
    "    \"--task_data_name\", env_vars['input_data_dir_name'],\n",
    "    \"--do_test\",\n",
    "]\n",
    "\n",
    "# Combine environment variables and include the current environment\n",
    "combined_env = {**env_vars, **os.environ}\n",
    "\n",
    "# Activate the conda environment and run the command\n",
    "try:\n",
    "    \n",
    "    # Run the main command\n",
    "    result = subprocess.run(command, env=combined_env, capture_output=True, text=True, check=True)\n",
    "\n",
    "    # Print the output if the command is successful\n",
    "    print(\"Output:\", result.stdout)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    # Handle the case where the subprocess returns a non-zero exit status\n",
    "    print(\"Error: The command failed with the following message:\")\n",
    "    print(\"Output:\", e.stdout)\n",
    "    print(\"Error:\", e.stderr)\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any other exceptions\n",
    "    print(\"An unexpected error occurred:\", str(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpnlg_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
