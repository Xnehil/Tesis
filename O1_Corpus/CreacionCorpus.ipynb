{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesarOracion(bloque):\n",
    "    #Eliminar punttuación y pasar a minúsculas\n",
    "    bloque = re.sub(r'[^\\w\\s]', '', bloque)\n",
    "    bloque = bloque.lower()\n",
    "    return bloque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por cada archivo en la carpeta textos, contar oraciones\n",
    "data = {}\n",
    "primera = True\n",
    "id = locutor = texto = palabras = traduccion = morfologia = pos = None\n",
    "\n",
    "for filename in os.listdir('../textos'):\n",
    "    #Si el archivo es un .txt\n",
    "    if filename.endswith('.txt'):\n",
    "        #Se abre el archivo\n",
    "        #Saltar el archivo 'textos/DICCIONARIOISKONAWA7.txt' porque no es un archivo de texto\n",
    "        if filename == 'DICCIONARIOISKONAWA7.txt':\n",
    "            continue\n",
    "        with open('../textos/'+filename, encoding='utf-8') as file:\n",
    "            #Se lee el archivo\n",
    "            texto = file.read()\n",
    "            #Por cada linea en el archivo\n",
    "            for line in texto.split('\\n'):\n",
    "                #Skip si la linea es solo espacios en blanco o saltos de linea\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                tipo_match = re.search(r'^\\\\\\S*', line)\n",
    "                if tipo_match:\n",
    "                    tipo = tipo_match.group()\n",
    "                    # Remove the tipo from the line to get the oracion\n",
    "                    oracion = re.sub(r'^\\\\\\S* ', '', line)\n",
    "                    #Quitar espacios en blnaco\n",
    "                    oracion = oracion.strip()\n",
    "                    \n",
    "                    # Process the oracion based on the tipo\n",
    "                    if tipo == '\\\\ref':\n",
    "                        id = oracion\n",
    "                        # Append the previous data before resetting variables\n",
    "                        if not primera:\n",
    "                            key = f\"{filename}_{id}\"\n",
    "                            data[key] = {\n",
    "                                'id': id, \n",
    "                                'locutor': locutor, \n",
    "                                'texto': texto, \n",
    "                                'palabras': palabras, \n",
    "                                'traduccion': traduccion, \n",
    "                                'morfologia': morfologia, \n",
    "                                'pos': pos,\n",
    "                                'archivo': filename\n",
    "                            }\n",
    "                        primera = False\n",
    "                    elif tipo == '\\\\ELANParticipant':\n",
    "                        locutor = oracion\n",
    "                    elif tipo == '\\\\trs':\n",
    "                        texto = procesarOracion(oracion)\n",
    "                    elif tipo == '\\\\tx':\n",
    "                        palabras = oracion\n",
    "                    elif tipo == '\\\\ft':\n",
    "                        traduccion = oracion\n",
    "                    elif tipo == '\\\\mb':\n",
    "                        morfologia = oracion\n",
    "                    elif tipo == '\\\\ps':\n",
    "                        pos = oracion\n",
    "                    else:\n",
    "                        continue\n",
    "            primera = True\n",
    "if not primera:\n",
    "    key = f\"{filename}_{id}\"\n",
    "    data[key] = {\n",
    "        'id': id, \n",
    "        'locutor': locutor, \n",
    "        'texto': texto, \n",
    "        'palabras': palabras, \n",
    "        'traduccion': traduccion, \n",
    "        'morfologia': morfologia, \n",
    "        'pos': pos,\n",
    "        'archivo': filename\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame(data)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora solo los .eaf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los archivos que terminan en .eaf y no tienen un archivo .txt\n",
    "archivos = []\n",
    "for filename in os.listdir('../textos'):\n",
    "    if filename.endswith('.eaf'):\n",
    "        if not os.path.exists('../textos/'+filename[:-4]+'.txt'):\n",
    "            archivos.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_eaf(filename, data):\n",
    "    locutor = texto = palabras = traduccion = morfologia = pos = id = None\n",
    "    dentro_tier = False\n",
    "    with open('../textos/'+filename, encoding='utf-8') as file:\n",
    "        texto = file.read()\n",
    "        #Cada archivo eaf es un xml. Nos interesa el valor de los atributos 'ANNOTATION_VALUE' de los elementos 'TIER' que tengan el atributo 'TIER_ID' igual a 'trsx@algo'\n",
    "        #Por cada linea en el archivo\n",
    "        for line in texto.split('\\n'):\n",
    "            #Skip si la linea es solo espacios en blanco o saltos de linea\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            #Buscar fin de tier\n",
    "            end_tier_match = re.search(r'</TIER>', line)\n",
    "            if end_tier_match:\n",
    "                dentro_tier = False\n",
    "\n",
    "            if dentro_tier:\n",
    "                if tier_id.startswith('trs@'):\n",
    "                    #Cosa de transcripción original\n",
    "                    alignable_annotation_match = re.search(r'<ALIGNABLE_ANNOTATION[^>]*ANNOTATION_ID=\"([^\"]+)\"', line)\n",
    "                    if alignable_annotation_match:\n",
    "                            annotation_id = alignable_annotation_match.group(1)\n",
    "                            id = annotation_id\n",
    "                    if id is not None:\n",
    "                        annotation_value_match = re.search(r'<ANNOTATION_VALUE>([^<]+)</ANNOTATION_VALUE>', line)\n",
    "                        if annotation_value_match:\n",
    "                            texto = procesarOracion(annotation_value_match.group(1))\n",
    "                            key = f\"{filename}_{id}\"\n",
    "                            data[key] = {\n",
    "                                'id': id, \n",
    "                                'locutor': locutor, \n",
    "                                'texto': texto, \n",
    "                                'palabras': palabras, \n",
    "                                'traduccion': traduccion, \n",
    "                                'morfologia': morfologia, \n",
    "                                'pos': pos,\n",
    "                                'archivo': filename\n",
    "                            }\n",
    "                elif tier_id.startswith('tx@'):\n",
    "                    ref_annotation_match = re.search(r'<REF_ANNOTATION[^>]*ANNOTATION_ID=\"([^\"]+) ANNOTATION_REF=\"([^\"]+)\"', line)\n",
    "                    if ref_annotation_match:\n",
    "                        annotation_id = ref_annotation_match.group(1)\n",
    "                        #Buscar en data el elemento con el id igual a annotation_ref y archivo igual a filename\n",
    "                        annotation_ref = ref_annotation_match.group(2)\n",
    "                        key = f\"{filename}_{annotation_ref}\"\n",
    "                    if annotation_id is not None:\n",
    "                        annotation_value_match = re.search(r'<ANNOTATION_VALUE>([^<]+)</ANNOTATION_VALUE>', line)\n",
    "                        if annotation_value_match:\n",
    "                            palabras = annotation_value_match.group(1)\n",
    "                            data[key]['palabras'] = palabras\n",
    "                elif tier_id.startswith('ft@'):\n",
    "                    #Cosa de traducción\n",
    "                    ref_annotation_match = re.search(r'<REF_ANNOTATION[^>]*ANNOTATION_ID=\"([^\"]+) ANNOTATION_REF=\"([^\"]+)\"', line)\n",
    "                    if ref_annotation_match:\n",
    "                        annotation_id = ref_annotation_match.group(1)\n",
    "                        #Buscar en data el elemento con el id igual a annotation_ref y archivo igual a filename\n",
    "                        annotation_ref = ref_annotation_match.group(2)\n",
    "                        key = f\"{filename}_{annotation_ref}\"\n",
    "                    if annotation_id is not None:\n",
    "                        annotation_value_match = re.search(r'<ANNOTATION_VALUE>([^<]+)</ANNOTATION_VALUE>', line)\n",
    "                        if annotation_value_match:\n",
    "                            traduccion = annotation_value_match.group(1)\n",
    "                            data[key]['traduccion'] = traduccion\n",
    "            else:\n",
    "                #Buscamos primero un elemento 'TIER' que tenga el atributo 'TIER_ID' igual a 'trs@algo'\n",
    "                tier_match = re.search(r'<TIER[^>]*PARTICIPANT=\"([^\"]+)\"[^>]*TIER_ID=\"([^\"]+)\"', line)\n",
    "                if tier_match:\n",
    "                    locutor = tier_match.group(1)\n",
    "                    tier_id = tier_match.group(2)\n",
    "                    if tier_id.startswith('trs@'):\n",
    "                        dentro_tier = True\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: Juanita, TIER_ID: trs@Juanita\n",
      "Participant: Nelita, TIER_ID: trs@Nelita\n",
      "Participant: Isabel, TIER_ID: trs@Isabel\n",
      "Participant: Elias, TIER_ID: trs@Elias\n",
      "Participant: Juanita, TIER_ID: tx@Juanita\n",
      "Participant: Juanita, TIER_ID: ft@Juanita\n",
      "Participant: Nelita, TIER_ID: tx@Nelita\n",
      "Participant: Nelita, TIER_ID: ft@Nelita\n",
      "Participant: Isabel, TIER_ID: tx@Isabel\n",
      "Participant: Isabel, TIER_ID: ft@Isabel\n",
      "Participant: Elias, TIER_ID: tx@Elias\n",
      "Participant: Elias, TIER_ID: ft@Elias\n",
      "Participant: juanita, nelita, isabel, TIER_ID: trs@juanitanelitaisabel\n",
      "Participant: juanita, nelita, isabel, TIER_ID: tx@juanitanelitaisabel\n",
      "Participant: juanita, nelita isabel, TIER_ID: ft@juanitanelitaisabel\n",
      "Participant: Nelita, TIER_ID: trs@Nelita\n",
      "Participant: Nelita, TIER_ID: tx@Nelita\n",
      "Participant: Nelita, TIER_ID: ft@Nelita\n",
      "Participant: Roberto, TIER_ID: trs@Roberto\n",
      "Participant: Roberto, TIER_ID: tx@Roberto\n",
      "Participant: Roberto, TIER_ID: ft@Roberto\n",
      "Participant: Nelita, TIER_ID: trs@Nelita\n",
      "Participant: Nelita, TIER_ID: tx@Nelita\n",
      "Participant: Nelita, TIER_ID: ft@Nelita\n",
      "Participant: Roberto, TIER_ID: trs@Roberto\n",
      "Participant: Roberto, TIER_ID: tx@Roberto\n",
      "Participant: Roberto, TIER_ID: ft@Roberto\n",
      "Participant: Nelita, TIER_ID: trs@Nelita\n",
      "Participant: Nelita, TIER_ID: tx@Nelita\n",
      "Participant: Nelita, TIER_ID: ft@Nelita\n",
      "Participant: Roberto, TIER_ID: trs@Roberto\n",
      "Participant: Roberto, TIER_ID: tx@Roberto\n",
      "Participant: Roberto, TIER_ID: ft@Roberto\n",
      "Participant: Nelita, TIER_ID: trs@Nelita\n",
      "Participant: Nelita, TIER_ID: tx@Nelita\n",
      "Participant: Nelita, TIER_ID: ft@Nelita\n",
      "Participant: Jaime, TIER_ID: trs@Jaime\n",
      "Participant: Jaime, TIER_ID: tx@Jaime\n",
      "Participant: Jaime, TIER_ID: ft@Jaime\n",
      "Participant: Roberto, TIER_ID: trs@Roberto\n",
      "Participant: Roberto, TIER_ID: tx@Roberto\n",
      "Participant: Roberto, TIER_ID: ft@Roberto\n",
      "Participant: Pablo, TIER_ID: trs@Pablo\n",
      "Participant: Pablo, TIER_ID: tx@Pablo\n",
      "Participant: Pablo, TIER_ID: ft@Pablo\n",
      "Participant: Roberto, TIER_ID: trs@Roberto\n",
      "Participant: Roberto, TIER_ID: tx@Roberto\n",
      "Participant: Roberto, TIER_ID: ft@Roberto\n",
      "Participant: Pablo, TIER_ID: trs@Pablo\n",
      "Participant: Pablo, TIER_ID: tx@Pablo\n",
      "Participant: Pablo, TIER_ID: ft@Pablo\n",
      "Participant: Roberto, TIER_ID: trs@Roberto\n",
      "Participant: Roberto, TIER_ID: tx@Roberto\n",
      "Participant: Roberto, TIER_ID: ft@Roberto\n",
      "Participant: Pablo, TIER_ID: trs@Pablo\n",
      "Participant: Pablo, TIER_ID: tx@Pablo\n",
      "Participant: Pablo, TIER_ID: ft@Pablo\n"
     ]
    }
   ],
   "source": [
    "for archivo in archivos:\n",
    "    leer_eaf(archivo, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "\n",
    "def is_spanish(text):\n",
    "    try:\n",
    "        return detect(text) == 'es'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "#Quitar de df las filas que están en df_spanish\n",
    "df = df[~df['texto'].apply(is_spanish)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "#Crear un corpus con los textos en df\n",
    "corpus = PlaintextCorpusReader('../corpus', '.*')\n",
    "for i, row in df.iterrows():\n",
    "    #Crear un archivo con el id como nombre y el texto como contenido\n",
    "    with open(f'../corpus/{row[\"id\"]}.txt', 'w') as file:\n",
    "        file.write(row['texto'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
